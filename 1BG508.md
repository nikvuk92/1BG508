# PGA Course Autumn 2022
# Instructions for project work
The goal of this population genomics project is to familiarize you with the workflows, different types of commonly used analyses as well as a way of thinking about how one approaches questions such as trying to explain the underlying forces that affect populations in general.

The structure of the project work will be organized as follows: 

- each group consists of two students;
- you need an username & password to log into Uppmax;
- up to you to decide if you want to work on your own laptops or in Hubben;
- we have an introductory meeting where we discuss the framework of the exercize in depth;
- in the few weeks you have until the course ends, we will set up meeting times that work for all of us;
- feel free to send in emails with specific questions if something is not working or you're just curious;
- the end product should be a Scientific report of ~10 pages, including Abstract, Introduction, Materials & Methods, Results, Discussion, References, Appendices (length is not crucial here, substance is);
- A short presentation (date will be set);
- the deadline for the written report is the day of the presentation.

# Unmasking the mystery
The specific point of the exercise is for you to identify the populations you have been given in the **'Unknown.fam'**. In order to achieve this, you have been provided a bunch of references (three different datasets) that should come in handy as a way to compare the unknown to the known. Both reference and target populations can be found in the DATA directory:
```
/proj/uppmax2022-2-21/PGA_2022/DATA/Reference_datasets
/proj/uppmax2022-2-21/PGA_2022/DATA/Mystery_populations
```
Helpful scripts are there to aid you on your quest can be found:
```
/proj/uppmax2022-2-21/PGA_2022/SCRIPTS
```
The unknown samples are a mysterious bunch. They look different from the rest don't they? (*hint - check the genotyping rate - i.e. missingness*).
Your first task is to figure out what types of samples you have stumbled upon and why they are (potentially) very valuable, yet they look the way they do (*the real Sherlocks among you would have noticed by now something odd by just glancing at their names!*) 
**Beware** - it is vital to not apply any filters to your unknown samples - we don't know anything about them at this point! 

In the steps that will lead you towards unmasking the unknown populations you will need to: 

1. Check for related individuals in your **reference dataset** 
2. Filter the related individuals from the **reference dataset** - *we have nothing against family, but individuals that are in close kinship will affect our downstream analysis and we don't want that*.
3. Filter the **reference** individuals & SNPs (missingness, HWE, MAF) - *word of caution: do not apply the 'maf' filtering until you have your final references dataset!*
   *Remember: The **unknown** samples **do not** go through any filtering!*
4. Merging the reference datasets (*When merging your reference dataset you want to make sure to only keep the overlapping SNPs*)
6. Unify SNP names across your dataset - change the SNP name into the names based on position. This is needed when merging datasets from different SNP chips (the same position can have different names on different chips). 
7. After merging together your reference dataset and you've finished filtering it - merge it together with your **unknown** data.
8. Before running PCA you need to prune your data for SNPs in LD (pruning is explained in the admixture manual https://dalexander.github.io/admixture/admixture-manual.pdf)
9. Run a PCA onjust on your "reference" dataset as well as on the combined "reference + Unknown dataset".
10. Run a projected PCA - but why?
11. Run Admixture (remember - Admixture takes a lot of time! Organize your time wisely)
12. Read up on some literature - it will help for writing the report! Pay special attention to the key figures in them.
[Schlebusch 2012](https://pubmed.ncbi.nlm.nih.gov/22997136/)
[Gurdasani_2015](https://www.nature.com/articles/nature13997) 
[Patin 2017](https://science.sciencemag.org/content/356/6337/543)
13. Don't panic - there's plenty of time. Or is there?

# Population structure analysis
Before we start here are some basic Unix/Linux commands if you are not used to working in a Unix-style terminal:
### Moving about:
```
    cd – change directory
    pwd – display the name of your current directory
    ls – list names of files in a directory
```
### File/Directory manipulations:
```
    cp – copy a file
    mv – move or rename files or directories
    mkdir – make a directory
    rm – remove files or directories
    rmdir – remove a directory
```
Display file content:
```
    cat - concatenate file contents to the screen or to a file
    less - open file for viewing
```	

## PART 1 Filtering and merging population genomic data using PLINK  	    

FYI: Link to PLINK site:[https://www.cog-genomics.org/plink2](https://www.cog-genomics.org/plink2)

PLINK is a software for fast and efficient filtering, merging, editing of large SNP datasets, and exports to different outputs directly usable in other programs. Stores huge datasets in compact binary format from which it reads-in data very quickly.

Running the program:

If working on Rackham type in the following:
```
module load bioinfo-tools
module load plink/1.90b4.9 

```
The software is already pre-installed on Rackham, you just have to load it

Try it:
```
plink
```

#### This is what a basic command structure looks like in Plink: 
``` 
plink --filetypeflag filename --commandflag commandspecification --outputfilecommand --out outputfilename
```
For example to do filtering of missing markers at 10% frequency cutoff (reading-in a bed format file called file1, doing the filtering, writing to a ped format file called file2):
```
plink --bfile file1 --geno 0.1 --recode --out file2
```

#### Input formats:
File format summary:
ped format: usual format (.ped and .fam)
.ped contain marker and genotype info and .fam files contain sample info
bed format: binary/compact ped format (.fam .bim and .bed)
(.fam - sample info  .bim - marker info  and .bed - genotype info in binary format
tped format: transposed ped format (.tfam and .tped files)
tfam sample info, .tped marker and genotype info in transposed format
lgen format: long format (see manual, not used that often)


Setup
Navigate to the directory you want to work in.
```
cd path (change directory)
mkdir directory_name (create a new directory)
```
If you don't already have a working directory for this course then create one now:

```
cd /proj/uppmax2022-2-21 #Uppmax project for this course
mkdir your_unique_team_name
```

## Exercise 1 - Getting your exercise datasets. Reading in bed file and converting to other formats 


#### The course material can be found at the following path:

```
/proj/uppmax2022-2-21/PGA_2022
```

Copy the datasets from the directory “DATA” to your working folder by **changing** the command below while you are in your working folder. The **dot** means copy the contents "here":
```
cp /full_path_to_course_material/unk1.bed .
cp /full_path_to_course_material/unk1.bim .
cp /full_path_to_course_material/unk1.fam .
```

These files contain SNPs from 16 unknown individuals in bed file format. You are going to figure out the ancestry of these population groups during this practical.

Look at the `.bim` (markers) and `.fam` (sample info) files by typing:

```
less Unknown.bim
``` 

do the same for the `.fam` file

```
less Unknown.fam 
```
As mentioned before the `.bim` file store the variant markers present in the data and `.fam` lists the samples. (you can try to look at the .bed as well, but this file is in binary format and cannot be visualized as text if you want to see the specific genotype info you must export the bed format to a ped format)

Read in a  bed file dataset and convert to ped format by typing/pasting in:

```
plink --bfile Unknown --recode --out Unknown_ped 
```

#### Look at the info that Plink prints to the screen. How many SNPs are there in the data? How many individuals? How much missing data?

Look at the missingness information of each individual and SNP by typing:

```
plink  --bfile Unknown --missing --out test1miss
```

Look at the two generated files by using the `less` command (q to quit)

```
less test1miss.imiss
less test1miss.lmiss
```

The `.imiss` contains the individual missingness and the `.lmiss` the marker missingness
Do you understand the columns of the files? The last three columns are the number of missing, the total, and the fraction of missing markers and individuals for the two files respectively

#### Look at the first few lines of the newly generated .map (sample info) and .ped (marker and genotype info) files using the more command as demonstrated above

Read in bed/ped file and convert to tped

```
plink --bfile Unknown --recode transpose --out Unknown_tped 
plink --file Unknown_ped --recode transpose --out Unknown_tped 
```

Do you see the difference in the two commands above for reading from a bed (--bfile) and reading from a ped (--file) file. Which one takes longer to read-in?

Look at the first few lines of the  `.tfam` and `.tped` files by using the `less` command

#### Can you see what symbol is used to encode missing data?

Note- try to always work with bed files, they are much smaller and takes less time to read in. 
See this for yourself by inspecting the difference in file sizes:

```
ls -lh * 
```

Plink can convert to other file formats as well, you can have a look in the manual for the different types of conversions

### Data Merging

The next step would be to start merging your data with comparative datasets. But first you need to merge the three reference datasets to eachother, filter and clean-up, before you finally merge the **combined** to the **Unknown** dataset. 

# A word of advice:

Usually, when you merge your data with another dataset there are strand issues. The SNPs in the other dataset might be typed on the reverse DNA strand and yours on the forward, or vice versa. Therefore you need to flip the strand to the other orientation for all the SNPs where there is a strand mismatch. One should not flip C/G and A/T SNPs because one cannot distinguish reverse and forward orientation (i.e. C/G becomes G/C unlike other SNPs i.e. G/T which become C/A). Therefore before merging and flipping all A/T and C/G SNPs must be excluded. However, this can be a problem since some of your SNPs in your dataset may be monomorphic when you don't apply the MAF filter. I.E in the bim file they will appear as C 0 (with 0 meaning missing). So you don't know what kind of SNP it is, it can be C G or C T for instance if it is C G it needs to be filtered out but not if it is C T.
Therefore, before merging our data to other datasets it is important to first merge your data with a fake / reference_individual, that you prepare, which is heterozygous at every SNP position. This “fake” reference individual you can easily prepare from the SNP info file you get from the genotyping company or your own genomics processing software (such as Genome Studio from Illumina). You can also prepare it from data downloaded for each SNP from a web-database such as dbSNP. Due to time constraints, we are now skipping this step and continuing to the next exercise. You can, however, do that optionally on your own time. It is anyways good to know how it's done.

```
plink --bfile /proj/uppmax2022-2-21/PGA_2022/full_path_to_YOUR_OWN_directory/Reference_datasets/Schlebusch_2012/Schlebusch_2012 --bmerge /proj/uppmax2022-2-21/PGA_2022/full_path_to_YOUR_directory/Reference_datasets/Patin_2017/Patin_2017 --recode transpose --allow-no-sex --out Merged_Patin_Schlebusch
```
Now merge the third dataset to the ```Merged_Patin_Schlebusch``` dataset using the same logic. When you have done that continue with the filtering step.

### Filtering for missing data:

First, we filter for marker missingness:

Paste in the command below to filter out markers with more than 10% missing data

```
plink --bfile combined_dataset --geno 0.1 --make-bed --out combined_dataset2 
```

Look at the screen output, how many SNPs were excluded?

### Now we will filter for individual missingness:

Paste in the command below to filter out individual missingness

```
plink --bfile combined_dataset2 --mind 0.15 --make-bed --out combined_dataset3 
```

Look at the screen output, how many individuals were excluded?

### MAF filtering:
To filter for minimum allele frequency is not always optimal, especially if you are going to merge your data with other datasets in which the alleles might be present. But we will apply a MAF filter in this case
(remember not to filter the 'Unknown' samples)

Filter data for a minimum allele frequency of 1% by pasting in:

```
plink --bfile combined_dataset3 --maf 0.01 --make-bed --out combined_dataset4 
```

How many SNPs are left?

### Now we will filter for SNPs out of Hardy-Weinberg equilibrium. 
Most likely, SNPs out of HWE usually indicates problems with the genotyping. However, to avoid filtering out SNPs that are selected for/against in certain groups (especially when working with case/control data) filtering HWE per group is recommended. After, only exclude the common SNPs that fall out of the HWE in the different groups - (OPTIONAL). But for reasons of time, we will now just filter the entire dataset for SNPs that aren’t in HWE with a significance value of 0.001

```
plink --bfile combined_dataset4 --hwe 0.001 --make-bed --out combined_dataset5
```

Look at the screen. How many SNPs were excluded?

If you only what to look at the HWE stats you can do as follows. By doing this command you can also obtain the observed and expected heterozygosities. 

```
plink --bfile combined_dataset5 --hardy --out hardy_combined_dataset5
```
Look at file hardy_combined_dataset5.hwe, see if you understand the output?

There are additional filtering steps that you can go further. PLINK site on the side lists all the cool commands that you can use to treat your data. Usually, we also filter for related individuals and do a sex-check on the X-chromosome to check for sample mix-ups. 

### Filtering out related individuals:

In the `SCRIPTS` folder, there is a script called `sbatch_KING.sh` that can be used to run [KING](http://people.virginia.edu/~wc9c/KING/manual.html) You can have a look inside for instructions on how to run the script. Check out the manual and try and figure out how the software works.
After you have run the script have a look at the produced output files and figure out how to remove the related individuals.

### When merging your reference dataset you want to make sure to only keep overlapping SNPS <----------
The ```rename_SNP.py``` script can be used on the `.bim` files to change the SNP name into the names based on position. This in needed when merging datasets from different chips since the same position can have different names on different chips.

### After you are done with all the filtering steps you can finally merge the filtered combined reference dataset with the Unknown.

```
plink --bfile /proj/uppmax2022-2-21/PGA_2022/full_path_to_YOUR_OWN_directory_and_the_final_filtered_combined_dataset --bmerge /proj/uppmax2022-2-21/PGA_2022/full_path_to_YOUR_directory/Mystery_populations/Unknown --recode transpose --allow-no-sex --out PopStrucIn1
```
Make sure to remember what your two final datasets are called. The one where you merged all the reference datasets and the one where you did that but also added the Unknown, which we are calling ```PopStrucIn1``` from now on. In the next steps you will need to produce a PCA of both.

###---> Look at your screen output. You will see that the Refpops only contains SNPs that overlap with a small percentage of the SNPs in the Unknown Pops data (~15 000 vs ~95 000). We will now again filter for SNP missingness to exclude all of the extra SNPs in the Unknown Pop data (Retain only the overlap).

How many SNPs are left for your analyses?

This is the final files for the next exercise. 
Now you have generated your input files for the next exercise which will deal with population structure analysis. You will look at the population structure of your unknown samples in comparison to the known reference populations from HapMap and HGDP.

=============================================================================

## PART 2: Population structure inference 
Using ADMIXTURE/PONG and principal component analysis with EIGENSOFT 

Admixture is a similar tool to STRUCTURE but runs much quicker, especially on large datasets.
Admixture runs directly from .bed or .ped files and needs no extra parameters pr file preparation. You do not specify burnin and repeats, ADMIXTURE exits when it converged on a solution (Delta< minimum value)

First, you have to load the module:

```
module load bioinfo-tools
module load ADMIXTURE/1.3.0

```


A basic ADMIXTURE run looks like this:

```
admixture -s time PopStrucIn1.bed 2
```

This command executes the program with a seed set from system clock time, it gives the input file (remember the extension) and the K value at which to run ADMIXTURE (2 in the previous command).

For ADMIXTURE you also need to run many iterations at each K value, thus a compute cluster and some scripting is useful.

Make a script from the code below to run Admixture for K = 2-6 with 3 iterations at each K value:


```
for i in {2..6};
    do                                                                                      
    for j in {1..3};                                                                                      
        do
        admixture -s time PopStrucIn1.bed ${i} 
        mv PopStrucIn1.${i}.Q PopStrucIn1.${i}.Q.${j};
        mv PopStrucIn1.${i}.P PopStrucIn1.${i}.P.${j};
    done
done
```

Look for a while at the screen output. You will see a short burin, followed by the repeats, and the run stops if delta goes below a minimum value. For K=2 this happens quickly, but the higher Ks take longer. If it takes too long for your liking (it probably will take around 5-10 min) press ctrl-C and copy the already prepaired output from the folder Data.

Look at the generated output files. What do they contain?

You can quickly look at your admixture output in `R` by opening R and then pasting in the code below. 

```
WD<-getwd()
setwd(WD)

k2_1 <- read.table("PopStrucIn1.2.Q.1")
k2_2 <- read.table("PopStrucIn1.2.Q.2")
k2_3 <- read.table("PopStrucIn1.2.Q.3")
k3_1 <- read.table("PopStrucIn1.3.Q.1")
k3_2 <- read.table("PopStrucIn1.3.Q.2")
k3_3 <- read.table("PopStrucIn1.3.Q.3")
k4_1 <- read.table("PopStrucIn1.4.Q.1")
k4_2 <- read.table("PopStrucIn1.4.Q.2")
k4_3 <- read.table("PopStrucIn1.4.Q.3")
k5_1 <- read.table("PopStrucIn1.5.Q.1")
k5_2 <- read.table("PopStrucIn1.5.Q.2")
k5_3 <- read.table("PopStrucIn1.5.Q.3")
k6_1 <- read.table("PopStrucIn1.6.Q.1")
k6_2 <- read.table("PopStrucIn1.6.Q.2")
k6_3 <- read.table("PopStrucIn1.6.Q.3")

pdf (file ="Admixture_Plot1.pdf", width =25, height = 40, pointsize =10)
par(mfrow=c(15,1))
barplot(t(as.matrix(k2_1)), col=rainbow(2),border=NA)
barplot(t(as.matrix(k2_2)), col=rainbow(2),border=NA)
barplot(t(as.matrix(k2_3)), col=rainbow(2),border=NA)
barplot(t(as.matrix(k3_1)), col=rainbow(3),border=NA)
barplot(t(as.matrix(k3_2)), col=rainbow(3),border=NA)
barplot(t(as.matrix(k3_3)), col=rainbow(3),border=NA)
barplot(t(as.matrix(k4_1)), col=rainbow(4),border=NA)
barplot(t(as.matrix(k4_2)), col=rainbow(4),border=NA)
barplot(t(as.matrix(k4_3)), col=rainbow(4),border=NA)
barplot(t(as.matrix(k5_1)), col=rainbow(5),border=NA)
barplot(t(as.matrix(k5_2)), col=rainbow(5),border=NA)
barplot(t(as.matrix(k5_3)), col=rainbow(5),border=NA)
barplot(t(as.matrix(k6_1)), col=rainbow(6),border=NA)
barplot(t(as.matrix(k6_2)), col=rainbow(6),border=NA)
barplot(t(as.matrix(k6_3)), col=rainbow(6),border=NA)
dev.off()
q()
N

```

This creates the pdf `Admixture_Plot1.pdf`. The bar plots have the individual K cluster assignment for the 3 iterations at K=2-6. The order of individuals is in file “PopStrucIn1.fam”

## PONG 

The method above is a way to quickly check your data, but you have to look at each iteration separately. This makes it hard to get a good overview of the results. We instead combine the different iterations using a software called PONG. 

A typical PONG command looks like this:


```
pong -m your_filemap.txt -i your_ind2pop.txt -n your_pop_order.txt -g
```

To be able to run PONG we thus need to generate three different files.

The first being the ***filemap***. This is the only input that is strictly required to run PONG. It consists of three columns.
From the PONG manual: 


```
Column 1. The runID, a unique label for the Q matrix (e.g. the string “run5_K7”).

Column 2. The K value for the Q matrix. Each value of K between Kmin and Kmax must
be represented by at least one Q matrix in the filemap; if not, pong will abort.

Column 3. The path to the Q matrix, relative to the location of the filemap. 
```

In order to create what we need we can run the following loop:


```
for i in {2..6};
do
    for j in {1..3};
    do
    echo -e "k${i}_r${j}\t$i\tPopStrucIn1.${i}.Q.${j}" >> unknown_filemap.txt
    done
done
```

The next file we need to create is the ***ind2pop*** file. It is just a list of which population each individual belongs to.
We have this information in the `.fam` file so we can just cut out the field we need:

```
cut -f 1 -d " " PopStrucIn1.fam > unknown_ind2pop.txt
``` 


The ***poporder*** file is a key between what your populations are called and what "Proper" name you want to show up in your final plot.
For us, it will look like this. *Note that the file needs to be tab-delimited, i.e separated by tabs. Below is just an example of what a poporder file should look like* 

```
CEU	European
Han	Han_Chinese 
MbutiPygmies	MbutiPygmies
San	San
Unknown1	Unknown1
Unknown11	Unknown11
Unknown3	Unknown3
Unknown5	Unknown5
YRI	Yoruba 

```
So just copy this into a file called `unknown_poporder.txt`

Now we have all the files we need. Time to run PONG.
PONG is available through the module system on Uppmax

```
module load pong 
```

Since we are several people who are going to run PONG at the same time we need to use a different port, otherwise, we will collide with each other. The default port for PONG is 4000. Any other free port will work, like 4001, 2, etc. Make sure you are using a uniq port before proceeding. If multiple people are trying to run PONG on the same port you have problems, so talk to your classmates and find a uniq port in the 4000s


```
pong -m unknown_filemap.txt -i unknown_ind2pop.txt -n unknown_poporder.txt -g --port YOUR_PORT_NUMBER_HERE
```


When PONG is done it will start hosting a webserver that displays the results at port 4000 by default:  http://localhost:4000. Pong needs to be running for you to look at the results, i.e. if you close it it will not work..

The web server is hosted on the same login node as you were running pong. In case you are unsure of which one that is you can use the command `hostename` to figure it out:

```
hostname
```

To view files interactively you need to have an X11 connection. So when you connect to rackham do:


```
ssh -AY YOUR_USERNAME_HERE@rackham.uppmax.uu.se

```

Make sure that you connect to the same rackham (i.e 1,2,3 etc) as you got from hostename.  
In a new tab (if you didn't put PONG in the background) type:

```
firefox http://localhost:YOUR_PORT_NUMBER
```


#### What do you see? What information does this give you about your misterious unknown populations? 
#### Can you figure out who they are?

Once you are finished with looking at the PONG output you can click and save some output to file and then close the program by hitting `ctrl - c` in the terminal tab running it. 



## Principal component Analysis with Eigensoft

The next population structure method we will look at is Principal Components Analysis with Eigensoft. 

You run eigensoft on the .bed format from plink. You only need to modify your .fam file a little for it to work in Eigensoft. The .bed and .map files you use directly as-is. The .fam file you change the extension to .pedind and you substitute the last column (-9 at the moment indicating missing phenotype) with population numbers. When assigning pop numbers do not use 1, 2 or 9. They are reserved for cases, controls and missing data in Eigensoft.

Paste this piece of code in to the terminal: <----------fix the code below

```
cut -d " " -f1-5 PopStrucIn1.fam >file1a
cut -d " " -f1 PopStrucIn1.fam >file2a
sed "s/Unknown1/51/g" <file2a | sed "s/Unknown3/53/g" | sed "s/Unknown5/55/g" | sed "s/Unknown11/61/g" | sed "s/CEU/81/g" | sed "s/YRI/82/g" | sed "s/Han/83/g" | sed "s/San/84/g" | sed "s/MbutiPygmies/85/g" >file3a
paste file1a file3a >fileComb
sed "s/\t/ /g" fileComb > PopStrucIn1.pedind
rm file1a; rm file2a; rm file3a; rm fileComb
```
It will make a `.pedind` file from your `.fam` file.

Furthermore, you need a parameter file to indicate your parameter options to EIGENSOFT.

Copy the prepared parameter file from the `DATA` directory to your working folder it's called 
`PopStrucIn1.par`

Open the parameter file and look at what is specified in it. At the start is the input/output files. Furthermore, we ask for the info for 10 PCs to be output, qtmode is set to NO to indicate more than one pop, we prune the SNPs based on LD for an r2 value of 0.2. We don't remove any outlying points and we limit the sample size to 20. This is important for PCA where there are groups with very large sample sizes since large sample sizes will distort the PC plot. It is best for PCA that sample sizes are as even as possible.

Run the smartpca package in Eigensoft by typing

```
module load eigensoft

smartpca -p PopStrucIn1.par
```

The outputfiles are .evec and .eval

In the `.evec` file is the main output for the number of PCs that you specified in the .par file. The first row is the Eigenvalues for each of your PCs the rest of the rows list your Pop:Ind specification, the PCs and their loadings and your PopNumber at the end. in the `.eval` is all the eigenvalues that were extracted. To work out the percentage of variation each PC explains, you divide your particular PC eigenvalue by the sum over all the eigenvalues.

We will plot the PCs in R now


Prep for R:

```
sed 1d PopStrucIn1.evec | sed  "s/:/   /g " >   PopStrucIn1.evecm
```


Open `R` and paste the following code to plot your PCs:

```
WD<-getwd()
setwd(WD)
## Define these
evec<- read.table ("PopStrucIn1.evecm")
eval<- read.table ("PopStrucIn1.eval")
namer <- "PopStrucIn1"
nrpc<-10
## Script start
totalev <-sum(eval)
aa <- array(NA,dim=c(nrpc,1))
for (i in 1:nrpc) {
    aa[i,1]<-format(round(((eval[i,1]/totalev)*100),3), nsmall = 3)}
pdf (file =paste(namer, "_PCA1.pdf", sep=""), width =10, height = 15, pointsize =12)
par(mfrow=c(3,2), oma=c(0,0,4,0))
plot (evec[,3], evec[,4],  pch = as.numeric(evec[,1]), cex = 1, col = as.numeric(evec[,1]), xlab=paste("PC1: ", aa[1,1], "%", sep=""), ylab=paste("PC2: ", aa[2,1], "%", sep=""))
legend("topright",  legend = unique(evec[,1]), text.col = "black", cex = 0.75, pch =unique(evec[,1]), col = unique(evec[,1]), xpd = TRUE, bty="n", )
abline(h=0, col="lightgray", lty=5, lwd=0.8); abline(v=0, col="lightgray", lty=5, lwd=0.8)
plot (evec[,5], evec[,6],  pch = as.numeric(evec[,1]), cex = 1, col = as.numeric(evec[,1]), xlab=paste("PC3: ", aa[3,1], "%", sep=""), ylab=paste("PC4: ", aa[4,1], "%", sep=""))
abline(h=0, col="lightgray", lty=5, lwd=0.8); abline(v=0, col="lightgray", lty=5, lwd=0.8)
plot (evec[,7], evec[,8],  pch = as.numeric(evec[,1]), cex = 1, col = as.numeric(evec[,1]), xlab=paste("PC5: ", aa[5,1], "%", sep=""), ylab=paste("PC6: ", aa[6,1], "%", sep=""))
abline(h=0, col="lightgray", lty=5, lwd=0.8); abline(v=0, col="lightgray", lty=5, lwd=0.8)
plot (evec[,9], evec[,10],  pch = as.numeric(evec[,1]), cex = 1, col = as.numeric(evec[,1]), xlab=paste("PC7: ", aa[7,1], "%", sep=""), ylab=paste("PC8: ", aa[8,1], "%", sep=""))
abline(h=0, col="lightgray", lty=5, lwd=0.8); abline(v=0, col="lightgray", lty=5, lwd=0.8)
plot (evec[,11], evec[,12],  pch = as.numeric(evec[,1]), cex = 1, col = as.numeric(evec[,1]), xlab=paste("PC9: ", aa[9,1], "%", sep=""), ylab=paste("PC10: ", aa[10,1], "%", sep=""))
abline(h=0, col="lightgray", lty=5, lwd=0.8); abline(v=0, col="lightgray", lty=5, lwd=0.8)
barplot (as.numeric(aa[,1]), xlab = "PC", ylab = "%Variation explained", axes=TRUE)
title(paste(namer, "PC plot"), outer=TRUE, cex.main = 1)
dev.off()
q()
```

See if you understand the code above. It plots PC1vsPC2 etc and puts labels on the plot.

Look at the output PDF. Do the results of your population PCA correspond to the population structure results you got from the ADMIXTURE plots? How many of the PCs do you think contain useful information. What part of the variation is represented by each of the PCs. Can you see the percentage variation that each PC explains?
It is a good idea to make two PCA plots - one with just the combined reference dataset and another one with the combined reference dataset + the Unknowns and compare them.

### Projected PCA

For our final analysis of the project you will first need merged plink files which contain your ancient individuals together with the references.
Secondly you need to create two files. One file with the list of all your reference pops and another with the ancient individuals. It's the information contained in second column of the `.fam` files that you want.

```
cut -f 2 -d " " reference_file.fam > pca_ref.pops
```

do the same for the aDNA ?????????? ones:

```
cut -f 2 -d " " reference_file.fam > pca_adna.pops
```

Now you need to create `.tfam, .tped` files from your`.bed, .fam, .bim` files.

In case you need to be refreshed:

```
plink --bfile "your_input" --recode transpose --out "your_output"
```

Once you have that run the ```prep_run_proj_pca.sh```

You will need to have the number of individuals in your modern reference and in your Unknown samples as argument 2 and 3

```
prep_run_proj_pca.sh basename_of_your_tfam_files num_modern num_unknown
```

E.g. if you have 100 modern indivudals and 2 unknown:

```
prep_run_proj_pca.sh my_tfam 100 2
```
Then you can run R (you first need to install ggplot2):

### R plotting ###??????????? fix the aDNA bit
```
R
library(ggplot2)
evec=read.table('plot.evec',skip=1,col.names=c("Ind","PC1","PC2","PC3","PC4","PC5","PC6","PC7","PC8","PC9","PC10","Pop","ModAnc"))
modern=subset(evec,evec[,ncol(evec)]=='Modern')
ancient=subset(evec,evec[,ncol(evec)]=='aDNA')
ggplot(modern,aes(x=PC1, y=PC2))+geom_text(data=modern,label=modern$Pop,colour='grey80', size=2.8)+theme_bw()+guides(fill=FALSE) + geom_point(data=ancient,aes(x=PC1,y=PC2,colour=Pop,shape=Pop,group=Pop), size=2.5)+scale_shape_manual(values=rep(1:14,3))
``` 

Look at the output PDF, what has changed? This should give you a further indication as to who your Unknown populations are.
